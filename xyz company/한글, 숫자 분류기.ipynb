{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한글, 숫자 분류기\n",
    "\n",
    "어떤 프로그래밍 언어이건 배우게 되면 처음 작성해보는 프로그램이 “Hello, World”를 출력해보는 것인데 컴퓨터 비전 관련 머신러닝의 “Hello, World”는 아마도 MNIST의 숫자 인식기일 것이다. 1999년에 처음 발표된 이 데이터셋은 사람이 쓴 숫자 이미지 7만 개로 구성되어 있으며 (6만 개는 훈련용이고 1만 개는 테스트용) 그동안 비전 관련 알고리즘의 벤치마크로 널리 쓰이고 있다. 아래 그림에서 그 데이터셋의 숫자 이미지를 일부 볼 수 있다. \n",
    "\n",
    "![image1.png](https://grepp-programmers.s3.ap-northeast-2.amazonaws.com/files/production/55ef65e6-2a2b-42f6-8a77-56da29983bef/image1.png)\n",
    "\n",
    "< MNIST에서 제공되는 숫자 이미지의 일부 예 - 위키피디아 MNIST_database>\n",
    "\n",
    "이 문제의 경우 이미지를 이미 처리해서 훈련용 데이터로 제공해주기 때문에 데이터의 전처리 과정이 필요하지 않다. 하지만 모든 머신러닝 모델 개발에서 중요한 부분은 바로 데이터의 전처리이다.\n",
    "\n",
    "이번 문제는 MNIST의 숫자 인식기 문제를 조금 다른 분야로 확장한 한글/숫자 인식기의 개발이다. 모든 MN IST처럼 알파벳 문자를 대상으로 하지는 않고 모두 14개의 한글 문자(‘가’부터 ‘하'까지의 14개의 글자)와 10개의 숫자(MNIST처럼 0부터 9까지의 10개의 숫자)를 대상으로 한다. MNIST의 숫자 인식기 문제와 또 다른 점은 훈련용 데이터들이 이미지 파일로 제공된다는 점으로  이미지 전처리 과정이 필요하다는 점이며 이는 코딩을 필요로 한다. 이미지의 크기는 36 * 36이다. \n",
    "\n",
    "모두 2800개의 이미지 데이터가 훈련용으로 제공되며 문자 인식 모델이 빌드된 후에는 이를 제출해야 하는 728개의 테스트 이미지에 적용하여 그 결과를 제출하면 된다.\n",
    "\n",
    "### 훈련/테스트 데이터 셋 설명\n",
    "\n",
    "이번 문제에 사용된 소문자 알파벳 이미지들을 일부 살펴보면 아래와 같다. 앞서 설명된 것처럼 14개의 한글 문자와 10개의 숫자로 구성되어 있다. 각 이미지들은 모두 36 * 36의 크기로 구성된다.\n",
    "\n",
    "![image2.png](https://grepp-programmers.s3.ap-northeast-2.amazonaws.com/files/production/aa294cbb-9190-4332-8ca5-345dbff1fad8/image2.png)\n",
    "\n",
    "data 디렉토리를 열면 아래와 같은 파일들을 볼 수 있다:\n",
    "\n",
    "* training.csv\n",
    "* test.csv\n",
    "* Images 폴더: 3528개의 png 파일들이 존재\n",
    "\n",
    "##### train.csv의 구성\n",
    "\n",
    "train.csv의 경우 헤더 라인 하나와 2800개의 이미지 파일 이름으로 구성되어 있으며 하나의 라인은 하나의 훈련용 이미지에 해당하며 각 라인의 첫 번째 필드(filename)는 해당 훈련용 이미지의 파일 이름이 된다. 두 번째 필드(label)는 이미지 파일에 해당하는 글자(0-9, ga-ha)가 된다. \n",
    "\n",
    "앞서 이야기했듯이 이미지의 픽셀 정보가 MNIST처럼 훈련용 데이터로 제공되지 않기 때문에 여러분들이 직접 이미지 파일을 읽어서 픽셀 데이터를 만들어내는 전처리 과정을 거쳐야 한다. 이미지 파일들은 images 폴더 안에 존재한다\n",
    "\n",
    "여러분이 해야 할 일은 이 파일들을 읽어 들이고 이 데이터를 바탕으로 앞의 필드에 주어진 글자를 예측하는 모델을 만드는 것이다. 예를 들어 이 파일의 처음 5라인을 보면 아래와 같다.\n",
    "\n",
    "| filename   | label |\n",
    "|------------|-------|\n",
    "| da_40.png  | da    |\n",
    "| ja_141.png | ja    |\n",
    "| 9_56.png   | 9     |\n",
    "| ba_90.png  | ba    |\n",
    "\n",
    "label과 그에 해당하는 문자는 다음과 같다.\n",
    "\n",
    "* 0~9: “0”부터 “9”까지의 숫자에 해당한다.\n",
    "* ga: “가\"\n",
    "* na: “나\"\n",
    "* da: “다\"\n",
    "* ra: “라\"\n",
    "* ma: “마\"\n",
    "* ba: “바\"\n",
    "* sa: “사\"\n",
    "* ah: “아\"\n",
    "* ja: “자\"\n",
    "* cha: “차\"\n",
    "* ca: “카\"\n",
    "* ta: “타\"\n",
    "* pa: “파\"\n",
    "* ha: “하\"\n",
    "\n",
    "##### test.csv의 구성\n",
    "\n",
    "앞서 만든 모델로 풀어야 하는 문제들이 들어있는 파일들이 바로 test.csv이다. 이 파일의 구성은 앞서 train.csv와 비슷하게 하나의 헤더 라인(filename)과 728개의 이미지 파일 라인으로 구성되어있다. 이 두 파일의 차이점은 test.csv에는 이미지에 해당하는 글자가 없이 이미지 파일의 이름만 있다는 점이다. 처음 5줄은 다음과 같다.\n",
    "\n",
    "| filename |\n",
    "|----------|\n",
    "| 1.png    |\n",
    "| 2.png    |\n",
    "| 3.png    |\n",
    "| 4.png    |\n",
    "\n",
    "여러분이 앞서 훈련용 데이터로 모델을 만든 뒤에 할 일은 여기 있는 이미지 파일들을 읽어서 그걸 모델의 입력으로 주고 나오는 예측값을 얻어내는 것이다. 이를 바탕으로 제출해야 할 파일의 포맷에 대해서 뒤에서 바로 설명한다.\n",
    "\n",
    "##### images 폴더\n",
    "\n",
    "모델 훈련에 필요한 2800개의 이미지와 나중에 훈련된 모델로 인식해서 인식 결과를 제출해야 하는 테스트 이미지 728개가 존재한다. 앞서 이야기했듯이 이 이미지들은 모두 36 * 36의 크기를 갖는다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 초기 코드 선택\n",
    "\n",
    "Python, R 중 본인의 선호 언어에 따라 코드를 작성하세요. 언어를 변경하는 방법이나 사용할 수 있는 라이브러리는 상단의 도움말 버튼에 나와있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>da_40.png</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ja_141.png</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9_56.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ba_90.png</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>na_18.png</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename label\n",
       "0   da_40.png    da\n",
       "1  ja_141.png    ja\n",
       "2    9_56.png     9\n",
       "3   ba_90.png    ba\n",
       "4   na_18.png    na"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기코드 - python\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 로드\n",
    "\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기코드 - R\n",
    "\n",
    "# 데이터 로드\n",
    "train <- read.csv('./data/train.csv')\n",
    "test <- read.csv('./data/test.csv')\n",
    "\n",
    "head(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과제\n",
    "\n",
    "채점을 위해 다음을 만족하는 csv 파일을 현재 디렉토리에 `submission.csv`라는 이름으로 저장해야 한다.\n",
    "\n",
    "여러분이 제출해야 하는 파일은 test.csv와 같은 수의 라인으로 구성이 되어야 하며 첫 번째 라인(헤더)은 다음과 같은 두 개의 필드로 구성이 되어야 한다:\n",
    " \n",
    "* filename\n",
    "* prediction\n",
    "\n",
    "먼저 첫 번째 컬럼으로 들어오는 filename은 test.csv에 들어오는 값들이 그대로 들어와야 한다. 두 번째 컬럼은 여러분이 훈련한 모델에 두 번째 컬럼에 해당하는 이미지 파일을 입력으로 주었을 때 나오는 예측값을 넣어주어야 한다 (즉 앞서 24개의 문자 중의 하나가 되어야 하며 train.csv에 있는 label 필드에 있는 값들을 사용한다).\n",
    "\n",
    "예를 들어 test.csv의 처음 다섯 라인이 아래와 같다면 \n",
    "\n",
    "| filename |\n",
    "|----------|\n",
    "| 1.png    |\n",
    "| 2.png    |\n",
    "| 3.png    |\n",
    "| 4.png    |\n",
    "\n",
    "제출하는 파일의 filename 필드는 test.csv에서 사용되었던 것들이 그대로 사용되어야 하며 prediction필드의 값으로는 해당 이미지의 인식 결과가 사용되어야 한다. 앞서 예로 사용한 test.csv에 해당하는 최종 제출 파일은 아래와 같은 형태를 갖추어야 한다.\n",
    "\n",
    "| filename | prediction |\n",
    "|----------|------------|\n",
    "| 1.png    | 0          |\n",
    "| 2.png    | ga         |\n",
    "| 3.png    | 1          |\n",
    "| 4.png    | da         |\n",
    "\n",
    "*주의* \n",
    "\n",
    "1. csv 파일의 컬럼은 반드시 filename, prediction 순이어야 한다.\n",
    "2. **index 순서(filename)는 반드시 `test.csv`에 나왔던 filename 순을 따라야 한다**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드를 작성해주세요\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "INPUT_SIZE = (36,36,3)\n",
    "NUM_CLASSES = 24\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=0.2)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2240 validated image filenames belonging to 24 classes.\n",
      "Found 560 validated image filenames belonging to 24 classes.\n",
      "Found 728 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Define data generators\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    directory=r\"./data/images\",\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(36, 36),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "valid_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    directory=r\"./data/images\",\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(36, 36),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test,\n",
    "    directory=r\"./data/images\",\n",
    "    x_col='filename',\n",
    "    class_mode=None,\n",
    "    target_size=(36, 36),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 36, 36, 32)        2432      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 36, 36, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 18, 18, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 18, 18, 32)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 18, 18, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 18, 18, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 9, 9, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 9, 9, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 4, 4, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 2, 2, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 24)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 691,800\n",
      "Trainable params: 690,072\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "\n",
    "initializer = 'he_normal'\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), padding='same', input_shape = INPUT_SIZE, kernel_initializer=initializer))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', kernel_initializer=initializer))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', kernel_initializer=initializer))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', kernel_initializer=initializer))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(256, kernel_initializer=initializer))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(128, kernel_initializer=initializer))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(NUM_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.0001), \n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 2.8713 - accuracy: 0.1714\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.06801, saving model to best_model.h5\n",
      "70/70 [==============================] - 8s 98ms/step - loss: 2.8713 - accuracy: 0.1714 - val_loss: 3.2850 - val_accuracy: 0.0680\n",
      "Epoch 2/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.8132 - accuracy: 0.5781\n",
      "Epoch 00002: val_accuracy improved from 0.06801 to 0.21691, saving model to best_model.h5\n",
      "70/70 [==============================] - 7s 95ms/step - loss: 1.8132 - accuracy: 0.5781 - val_loss: 2.7959 - val_accuracy: 0.2169\n",
      "Epoch 3/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.2541 - accuracy: 0.8219\n",
      "Epoch 00003: val_accuracy improved from 0.21691 to 0.43934, saving model to best_model.h5\n",
      "70/70 [==============================] - 7s 96ms/step - loss: 1.2541 - accuracy: 0.8219 - val_loss: 2.0872 - val_accuracy: 0.4393\n",
      "Epoch 4/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.9339 - accuracy: 0.8978\n",
      "Epoch 00004: val_accuracy improved from 0.43934 to 0.65441, saving model to best_model.h5\n",
      "70/70 [==============================] - 7s 98ms/step - loss: 0.9339 - accuracy: 0.8978 - val_loss: 1.5500 - val_accuracy: 0.6544\n",
      "Epoch 5/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.9549\n",
      "Epoch 00005: val_accuracy improved from 0.65441 to 0.77022, saving model to best_model.h5\n",
      "70/70 [==============================] - 7s 95ms/step - loss: 0.6920 - accuracy: 0.9549 - val_loss: 1.2127 - val_accuracy: 0.7702\n",
      "Epoch 6/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.5325 - accuracy: 0.9795\n",
      "Epoch 00006: val_accuracy improved from 0.77022 to 0.83824, saving model to best_model.h5\n",
      "70/70 [==============================] - 7s 95ms/step - loss: 0.5325 - accuracy: 0.9795 - val_loss: 0.9917 - val_accuracy: 0.8382\n",
      "Epoch 7/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.4159 - accuracy: 0.9879\n",
      "Epoch 00007: val_accuracy improved from 0.83824 to 0.84926, saving model to best_model.h5\n",
      "70/70 [==============================] - 7s 95ms/step - loss: 0.4159 - accuracy: 0.9879 - val_loss: 0.8622 - val_accuracy: 0.8493\n",
      "Epoch 8/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.3312 - accuracy: 0.9933\n",
      "Epoch 00008: val_accuracy improved from 0.84926 to 0.88051, saving model to best_model.h5\n",
      "70/70 [==============================] - 7s 95ms/step - loss: 0.3312 - accuracy: 0.9933 - val_loss: 0.7628 - val_accuracy: 0.8805\n",
      "Epoch 9/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.2635 - accuracy: 0.9987\n",
      "Epoch 00009: val_accuracy improved from 0.88051 to 0.88419, saving model to best_model.h5\n",
      "70/70 [==============================] - 7s 95ms/step - loss: 0.2635 - accuracy: 0.9987 - val_loss: 0.6720 - val_accuracy: 0.8842\n",
      "Epoch 10/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.2171 - accuracy: 0.9996\n",
      "Epoch 00010: val_accuracy improved from 0.88419 to 0.88971, saving model to best_model.h5\n",
      "70/70 [==============================] - 7s 96ms/step - loss: 0.2171 - accuracy: 0.9996 - val_loss: 0.6104 - val_accuracy: 0.8897\n",
      "Epoch 11/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.1808 - accuracy: 0.9996\n",
      "Epoch 00011: val_accuracy improved from 0.88971 to 0.89890, saving model to best_model.h5\n",
      "70/70 [==============================] - 7s 97ms/step - loss: 0.1808 - accuracy: 0.9996 - val_loss: 0.5717 - val_accuracy: 0.8989\n",
      "Epoch 12/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.1489 - accuracy: 0.9996\n",
      "Epoch 00012: val_accuracy improved from 0.89890 to 0.90257, saving model to best_model.h5\n",
      "70/70 [==============================] - 7s 96ms/step - loss: 0.1489 - accuracy: 0.9996 - val_loss: 0.5434 - val_accuracy: 0.9026\n",
      "Epoch 13/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 1.0000\n",
      "Epoch 00013: val_accuracy improved from 0.90257 to 0.90625, saving model to best_model.h5\n",
      "70/70 [==============================] - 7s 96ms/step - loss: 0.1277 - accuracy: 1.0000 - val_loss: 0.5015 - val_accuracy: 0.9062\n",
      "Epoch 14/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.1113 - accuracy: 1.0000\n",
      "Epoch 00014: val_accuracy did not improve from 0.90625\n",
      "70/70 [==============================] - 6s 92ms/step - loss: 0.1113 - accuracy: 1.0000 - val_loss: 0.4743 - val_accuracy: 0.9044\n",
      "Epoch 15/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0922 - accuracy: 1.0000\n",
      "Epoch 00015: val_accuracy did not improve from 0.90625\n",
      "70/70 [==============================] - 6s 92ms/step - loss: 0.0922 - accuracy: 1.0000 - val_loss: 0.4556 - val_accuracy: 0.9026\n",
      "Epoch 16/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 1.0000\n",
      "Epoch 00016: val_accuracy did not improve from 0.90625\n",
      "70/70 [==============================] - 6s 92ms/step - loss: 0.0829 - accuracy: 1.0000 - val_loss: 0.4307 - val_accuracy: 0.9044\n",
      "Epoch 17/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 1.0000\n",
      "Epoch 00017: val_accuracy did not improve from 0.90625\n",
      "70/70 [==============================] - 6s 92ms/step - loss: 0.0725 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.9062\n",
      "Epoch 18/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 1.0000\n",
      "Epoch 00018: val_accuracy improved from 0.90625 to 0.91360, saving model to best_model.h5\n",
      "70/70 [==============================] - 7s 96ms/step - loss: 0.0671 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.9136\n",
      "Epoch 19/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 1.0000\n",
      "Epoch 00019: val_accuracy improved from 0.91360 to 0.91728, saving model to best_model.h5\n",
      "70/70 [==============================] - 7s 95ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.3951 - val_accuracy: 0.9173\n",
      "Epoch 20/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 1.0000\n",
      "Epoch 00020: val_accuracy improved from 0.91728 to 0.92647, saving model to best_model.h5\n",
      "70/70 [==============================] - 7s 95ms/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.3779 - val_accuracy: 0.9265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe47019cfd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "          validation_data=valid_generator,\n",
    "          validation_steps=STEP_SIZE_VALID,\n",
    "          epochs=20,\n",
    "          callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "728/728 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "\n",
    "STEP_SIZE_TEST=test_generator.n // test_generator.batch_size\n",
    "test_generator.reset()\n",
    "pred = model.predict(test_generator,\n",
    "                     steps=STEP_SIZE_TEST,\n",
    "                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predicted_class_indices=np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "728 728\n"
     ]
    }
   ],
   "source": [
    "print(len(filenames), len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "df=pd.DataFrame({\"filename\":filenames,\n",
    "                 \"prediction\":predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일 저장 예시 - python\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'write' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1767/2886731191.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# csv 파일 저장 예시 - R\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'write' is not defined"
     ]
    }
   ],
   "source": [
    "# csv 파일 저장 예시 - R\n",
    "write.csv(df, file='submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
